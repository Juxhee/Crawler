{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Connection\" : \"keep-alive\",\n",
    "    \"Cache-Control\" : \"max-age=0\",\n",
    "    \"sec-ch-ua-mobile\" : \"?0\",\n",
    "    \"DNT\" : \"1\",\n",
    "    \"Upgrade-Insecure-Requests\" : \"1\",\n",
    "    \"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n",
    "    \"Accept\" : \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    \"Sec-Fetch-Site\" : \"none\",\n",
    "    \"Sec-Fetch-Mode\" : \"navigate\",\n",
    "    \"Sec-Fetch-User\" : \"?1\",\n",
    "    \"Sec-Fetch-Dest\" : \"document\",\n",
    "    \"Accept-Encoding\" : \"gzip, deflate, br\",\n",
    "    \"Accept-Language\" : \"ko-KR,ko;q=0.9\"\n",
    "    }\n",
    " \n",
    "\n",
    "def dc_url_crawler(keyword,page_num):\n",
    "    url_list = []\n",
    "    date_list = []\n",
    "    for page in range(page_num+1):\n",
    "        url = f\"https://search.dcinside.com/post/p/{page}/sort/accuracy/q/{keyword}\"\n",
    "\n",
    "        res = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "        result_list = soup.find_all(\"ul\",class_='sch_result_list')\n",
    "        for i in result_list:\n",
    "            for j in i.find_all('span',class_='date_time'):\n",
    "                date = j.text\n",
    "                date_list.append(date)\n",
    "            href = i.find_all('a',class_='tit_txt')\n",
    "            for h in href:\n",
    "                url = h.attrs['href']\n",
    "                url_list.append(url)\n",
    "        time.sleep(3)\n",
    "    drop_date = [index for index, date in enumerate(date_list) if date <= '2019.01.01 00:00:00']\n",
    "    new_date = np.delete(date_list, drop_date, axis=0)\n",
    "    new_url = np.delete(url_list, drop_date, axis=0)\n",
    "    return new_url, new_date\n",
    "\n",
    "keyword = \"산업공학과\"\n",
    " \n",
    "new_url, new_date = dc_url_crawler(keyword,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_cralwer(url_list):\n",
    "    title_list = []\n",
    "    content_list = []\n",
    "    for url in url_list:\n",
    "        res = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "        title = soup.find('span',class_='title_subject').text\n",
    "        print(title)\n",
    "        content = soup.find('div',class_='write_div')\n",
    "        print(content.text)\n",
    "        title_list.append(title)\n",
    "        content_list.append(content)\n",
    "    df = pd.DataFrame({'title':title_list,'content':content})\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
