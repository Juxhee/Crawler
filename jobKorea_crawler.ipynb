{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from IPython.core.display import display, HTML\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jk_url_crawler(keyword,page_num):\n",
    "    url_list = []\n",
    "    date_list = []\n",
    "    for page in range(page_num+1):\n",
    "        url = f'https://www.jobkorea.co.kr/User/Qstn/TalkSearchWindow?Keyword={keyword}&OrderType=1&W_TypeCode=0&page={page}'\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, 'lxml')\n",
    "        content_area = soup.find_all(\"div\",class_='contArea')\n",
    "        author_area = soup.find_all('div',class_='post-cell-box')\n",
    "        for i in content_area:\n",
    "            href = i.find_all('a')\n",
    "            for h in href:\n",
    "                url = h.attrs['href']\n",
    "                url = 'https://www.jobkorea.co.kr/' + url\n",
    "                print(page)\n",
    "                print(url)\n",
    "                url_list.append(url)\n",
    "    \n",
    "        for i in author_area:\n",
    "            date = i.find('cell',class_='span')\n",
    "            print(date.text)\n",
    "            date_list.append(date.text)\n",
    "                \n",
    "        time.sleep(3)\n",
    "        driver.close()\n",
    "    find_s = '#'\n",
    "    drop_url = [i for i in range(len(url_list)) if find_s in url_list[i]]\n",
    "    url_list = np.delete(url_list, drop_url, axis=0)\n",
    "\n",
    "    return url_list, date_list\n",
    "\n",
    "keyword = \"산업공학과\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobKorea_crawler(new_url, new_date):\n",
    "    final_content = pd.DataFrame(columns = ['title','content','date'])\n",
    "    final_comment = pd.DataFrame(columns = ['comment','date'])\n",
    "\n",
    "    for i in range(len(new_url)):\n",
    "        print(i)\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(new_url[i])\n",
    "        res = requests.get(new_url[i])\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "        comment_list = []\n",
    "        title_list = []\n",
    "        content_list = []\n",
    "        date_content = []\n",
    "        date_comment = []\n",
    "        df1 = pd.DataFrame()\n",
    "        df2 = pd.DataFrame()\n",
    "        try : \n",
    "            title = soup.find('p',class_='tit').text\n",
    "            title_list.append(title)\n",
    "            content = soup.find('div',class_='cont').text\n",
    "            content_list.append(content)\n",
    "            date_content.append(new_date[i])\n",
    "            comment_area = soup.find_all('p',class_='cont')    \n",
    "            comment_list = []\n",
    "            for j in comment_area:\n",
    "                com = re.sub('(<([^>]+)>)', '', str(j))\n",
    "                comment_list.append(com)\n",
    "                date_comment.append(new_date[i])\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        except UnexpectedAlertPresentException as e:\n",
    "            print(e.__dict__[\"msg\"])\n",
    "            \n",
    "        \n",
    "        df1 = pd.DataFrame({'title':title_list,'content':content_list,'date':date_content})\n",
    "        df2 = pd.DataFrame({'comment':comment_list, 'date':date_comment})\n",
    "        final_content = pd.concat([final_content, df1])\n",
    "        final_comment = pd.concat([final_comment, df2])\n",
    "        driver.close()\n",
    "        time.sleep(3)\n",
    "    return final_content, final_comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
